#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                          â•‘
â•‘   HoloNet v3.0 â€” FIXED for True Permutation Conflict                                    â•‘
â•‘   with HoloRAID k-of-n Memory Storage                                                    â•‘
â•‘                                                                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘   THE PROBLEM (why v1.4 fails in Track A):                                              â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘   When training on Task t, the encoder drifts. Old memories (from Tasks 0..t-1)         â•‘
â•‘   were computed with OLD encoder states. At test time, we compute embeddings with       â•‘
â•‘   the CURRENT encoder, but query memories that used OLD encoders.                       â•‘
â•‘   â†’ Embedding mismatch â†’ Garbage retrieval â†’ Memory HURTS performance                   â•‘
â•‘                                                                                          â•‘
â•‘   THE FIX:                                                                               â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘   1. PER-TASK ENCODERS: Each task gets its own encoder (cloned and fine-tuned)          â•‘
â•‘   2. TASK INFERENCE: At test time, compute embeddings with ALL task encoders,           â•‘
â•‘      query each task's memory, use retrieval confidence to infer task                   â•‘
â•‘   3. TASK-CONDITIONED RETRIEVAL: Only use memories from the inferred task               â•‘
â•‘   4. CONFIDENCE GATING: If task inference is uncertain, reduce memory weight            â•‘
â•‘                                                                                          â•‘
â•‘   This approach does NOT use TaskUnpermute and works under true permutation conflict.   â•‘
â•‘                                                                                          â•‘
â•‘   Run: python holonet_v3_fixed.py                                                        â•‘
â•‘   Requires: torch, torchvision, numpy, matplotlib                                        â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import math
import random
import copy
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple
from functools import reduce
from collections import defaultdict

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset

import torchvision
import torchvision.transforms as transforms


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBALS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def banner():
    print("â•" * 90)
    print("  HoloNet v3.0 â€” FIXED for True Permutation Conflict")
    print("  Per-Task Encoders + Task Inference + Task-Conditioned Retrieval")
    print("â•" * 90)
    print(f"  Device: {DEVICE}")
    print(f"  PyTorch: {torch.__version__}")
    print()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART I: NUMBER THEORY UTILS (CRT for HoloRAID)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extended_gcd(a: int, b: int) -> Tuple[int, int, int]:
    if a == 0:
        return (b, 0, 1)
    g, x, y = extended_gcd(b % a, a)
    return (g, y - (b // a) * x, x)


def mod_inverse(a: int, m: int) -> int:
    g, x, _ = extended_gcd(a % m, m)
    if g != 1:
        raise ValueError(f"No modular inverse for {a} mod {m}")
    return x % m


def is_prime(n: int) -> bool:
    if n < 2:
        return False
    if n in (2, 3):
        return True
    if n % 2 == 0:
        return False
    r, d = 0, n - 1
    while d % 2 == 0:
        r += 1
        d //= 2
    for a in [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37]:
        if a >= n:
            continue
        x = pow(a, d, n)
        if x in (1, n - 1):
            continue
        for _ in range(r - 1):
            x = pow(x, 2, n)
            if x == n - 1:
                break
        else:
            return False
    return True


def next_prime(n: int) -> int:
    if n <= 2:
        return 2
    if n % 2 == 0:
        n += 1
    while not is_prime(n):
        n += 2
    return n


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART II: HoloRAID (CRT k-of-n storage)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class HoloRAIDConfig:
    Q: int = 65535
    n_shards: int = 5
    k_threshold: int = 3
    epsilon_h: int = 1
    use_secrecy: bool = False
    seed: int = 42

    p0: int = field(init=False)
    primes: List[int] = field(init=False)
    M_k: int = field(init=False)
    max_r: int = field(init=False)
    route_perm: List[int] = field(init=False)

    def __post_init__(self):
        self.p0 = next_prime(self.Q + self.epsilon_h + 1)

        self.primes = []
        candidate = self.p0 + 1
        while len(self.primes) < self.n_shards:
            p = next_prime(candidate)
            self.primes.append(p)
            candidate = p + 1

        sorted_primes = sorted(self.primes)
        self.M_k = reduce(lambda a, b: a * b, sorted_primes[: self.k_threshold], 1)
        M_k_minus_1 = (
            reduce(lambda a, b: a * b, sorted_primes[: self.k_threshold - 1], 1)
            if self.k_threshold > 1
            else 1
        )
        if self.p0 * M_k_minus_1 >= self.M_k:
            raise ValueError("Asmuthâ€“Bloom condition violated; adjust primes/Q.")
        self.max_r = (self.M_k - self.Q - self.epsilon_h - 1) // self.p0

        rng = np.random.default_rng(self.seed)
        self.route_perm = list(map(int, rng.permutation(self.n_shards)))


class HoloRAIDMemory:
    """
    Stores UNIT-NORMALIZED embeddings with TASK IDs for task-conditioned retrieval.
    """

    def __init__(self, config: HoloRAIDConfig, embedding_dim: int):
        self.config = config
        self.embedding_dim = embedding_dim
        self.rng = np.random.default_rng(config.seed)

        self.entries: List[Dict[str, Any]] = []
        self.shard_banks: List[List[np.ndarray]] = [[] for _ in range(config.n_shards)]

    def quantize_unit(self, embedding: np.ndarray) -> np.ndarray:
        e = embedding.astype(np.float32)
        e = np.clip(e, -1.0, 1.0)
        q = np.rint((e + 1.0) * 0.5 * float(self.config.Q)).astype(np.uint16)
        return q

    def dequantize_unit(self, quantized: np.ndarray) -> np.ndarray:
        e = (quantized.astype(np.float32) / float(self.config.Q)) * 2.0 - 1.0
        n = np.linalg.norm(e) + 1e-8
        return (e / n).astype(np.float32)

    def _crt_encode(self, values_uint16: np.ndarray) -> List[np.ndarray]:
        cfg = self.config
        s = values_uint16.astype(np.uint64) + np.uint64(cfg.epsilon_h)

        if cfg.use_secrecy:
            r = self.rng.integers(0, cfg.max_r + 1, size=values_uint16.shape, dtype=np.uint64)
            s_prime = s + r * np.uint64(cfg.p0)
        else:
            s_prime = s

        shares = []
        for p in cfg.primes:
            shares.append((s_prime % np.uint64(p)).astype(np.uint32))

        return [shares[cfg.route_perm[i]] for i in range(cfg.n_shards)]

    def _crt_decode_uint16(self, shards: List[np.ndarray], available_indices: List[int]) -> np.ndarray:
        cfg = self.config
        k = cfg.k_threshold
        if len(available_indices) < k:
            raise RuntimeError(f"Insufficient shards: {len(available_indices)} < {k}")

        use_indices = available_indices[:k]
        prime_indices = [cfg.route_perm[i] for i in use_indices]
        moduli = [int(cfg.primes[pi]) for pi in prime_indices]
        residues = [shards[i].astype(np.uint64) for i in use_indices]

        p0 = int(cfg.p0)

        x_mod_p0 = (residues[0] % np.uint64(p0)).astype(np.uint64)
        x_mods = [(residues[0] % np.uint64(mj)).astype(np.uint64) for mj in moduli]

        M_mod_p0 = moduli[0] % p0
        M_mods = [0] * k
        for j in range(1, k):
            M_mods[j] = moduli[0] % moduli[j]

        for i in range(1, k):
            mi = moduli[i]
            ri = residues[i]

            Mi_mod_mi = M_mods[i]
            inv = mod_inverse(Mi_mod_mi, mi)

            diff = (ri + np.uint64(mi) - (x_mods[i] % np.uint64(mi))) % np.uint64(mi)
            t = (diff * np.uint64(inv)) % np.uint64(mi)

            x_mod_p0 = (x_mod_p0 + (t % np.uint64(p0)) * np.uint64(M_mod_p0)) % np.uint64(p0)

            for j in range(i + 1, k):
                mj = moduli[j]
                x_mods[j] = (x_mods[j] + (t % np.uint64(mj)) * np.uint64(M_mods[j])) % np.uint64(mj)

            M_mod_p0 = (M_mod_p0 * (mi % p0)) % p0
            for j in range(i + 1, k):
                mj = moduli[j]
                M_mods[j] = (M_mods[j] * (mi % mj)) % mj

        s = (x_mod_p0.astype(np.int64) - cfg.epsilon_h) % (cfg.Q + 1)
        return s.astype(np.uint16)

    def store(self, embedding_unit: np.ndarray, label: int, task_id: int) -> int:
        q = self.quantize_unit(embedding_unit)
        shards = self._crt_encode(q)

        for b in range(self.config.n_shards):
            self.shard_banks[b].append(shards[b].copy())

        entry = {"index": len(self.entries), "label": int(label), "task_id": int(task_id)}
        self.entries.append(entry)
        return entry["index"]

    def retrieve(self, index: int, simulate_failures: int = 0) -> Tuple[np.ndarray, int, int]:
        if index < 0 or index >= len(self.entries):
            raise IndexError("memory index out of range")

        entry = self.entries[index]
        cfg = self.config

        available = list(range(cfg.n_shards))
        if simulate_failures > 0:
            max_fail = min(simulate_failures, len(available) - cfg.k_threshold)
            if max_fail > 0:
                failed = self.rng.choice(available, size=max_fail, replace=False)
                available = [b for b in available if b not in failed]

        shards = [self.shard_banks[b][index] for b in range(cfg.n_shards)]
        q = self._crt_decode_uint16(shards, available)
        emb = self.dequantize_unit(q)
        return emb, entry["label"], entry["task_id"]

    def retrieve_all_for_task(self, task_id: int, simulate_failures: int = 0) -> Tuple[np.ndarray, np.ndarray]:
        """Retrieve all embeddings and labels for a specific task."""
        embs, labels = [], []
        for i, entry in enumerate(self.entries):
            if entry["task_id"] == task_id:
                e, y, _ = self.retrieve(i, simulate_failures=simulate_failures)
                embs.append(e)
                labels.append(y)
        if len(embs) == 0:
            return np.zeros((0, self.embedding_dim), dtype=np.float32), np.zeros(0, dtype=np.int64)
        return np.array(embs), np.array(labels)

    def get_task_ids(self) -> List[int]:
        """Get list of unique task IDs in memory."""
        return list(set(e["task_id"] for e in self.entries))

    def count_for_task(self, task_id: int) -> int:
        """Count memories for a specific task."""
        return sum(1 for e in self.entries if e["task_id"] == task_id)

    def prune_to_size(self, max_entries: int, strategy: str = "per_task_class") -> int:
        if len(self.entries) <= max_entries:
            return 0
        if strategy != "per_task_class":
            raise ValueError("Pruning strategy locked to per_task_class.")

        buckets = defaultdict(list)
        for i, e in enumerate(self.entries):
            buckets[(e["task_id"], e["label"])].append(i)

        keep = set()
        per = max(1, max_entries // max(1, len(buckets)))
        for _, idxs in buckets.items():
            if len(idxs) <= per:
                keep.update(idxs)
            else:
                keep.update(self.rng.choice(idxs, size=per, replace=False))

        if len(keep) > max_entries:
            keep = set(self.rng.choice(sorted(list(keep)), size=max_entries, replace=False))

        new_entries: List[Dict[str, Any]] = []
        new_banks: List[List[np.ndarray]] = [[] for _ in range(self.config.n_shards)]

        for old_idx in sorted(keep):
            e = dict(self.entries[old_idx])
            e["index"] = len(new_entries)
            new_entries.append(e)
            for b in range(self.config.n_shards):
                new_banks[b].append(self.shard_banks[b][old_idx])

        self.entries = new_entries
        self.shard_banks = new_banks
        return 0

    def __len__(self) -> int:
        return len(self.entries)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART III: DATA â€” Permuted MNIST
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PermutedMNIST:
    def __init__(self, n_tasks: int = 10, n_train: int = 3000, n_test: int = 500, seed: int = 42):
        self.n_tasks = n_tasks
        self.n_train = n_train
        self.n_test = n_test
        self.rng = np.random.default_rng(seed)

        # Forward perms; task0 = identity
        self.perms: List[np.ndarray] = [np.arange(28 * 28)]
        for _ in range(n_tasks - 1):
            self.perms.append(self.rng.permutation(28 * 28))

        transform = transforms.Compose([transforms.ToTensor()])
        train_data = torchvision.datasets.MNIST("./data", train=True, download=True, transform=transform)
        test_data = torchvision.datasets.MNIST("./data", train=False, download=True, transform=transform)

        train_images = train_data.data.float().unsqueeze(1) / 255.0
        train_labels = train_data.targets
        test_images = test_data.data.float().unsqueeze(1) / 255.0
        test_labels = test_data.targets

        self.task_train: List[Tuple[torch.Tensor, torch.Tensor]] = []
        self.task_test: List[Tuple[torch.Tensor, torch.Tensor]] = []

        for t in range(n_tasks):
            tr_idx = self.rng.choice(len(train_images), size=n_train, replace=False)
            te_idx = self.rng.choice(len(test_images), size=n_test, replace=False)

            tr_x = self._apply_perm(train_images[tr_idx], t)
            tr_y = train_labels[tr_idx]
            te_x = self._apply_perm(test_images[te_idx], t)
            te_y = test_labels[te_idx]

            self.task_train.append((tr_x, tr_y))
            self.task_test.append((te_x, te_y))

    def _apply_perm(self, images: torch.Tensor, task_id: int) -> torch.Tensor:
        perm = self.perms[task_id]
        B = images.shape[0]
        flat = images.view(B, -1)
        flat = flat[:, perm]
        return flat.view(B, 1, 28, 28)

    def get_task_loaders(self, task_id: int, batch_size: int) -> Tuple[DataLoader, DataLoader]:
        tr_x, tr_y = self.task_train[task_id]
        te_x, te_y = self.task_test[task_id]
        tr_loader = DataLoader(TensorDataset(tr_x, tr_y), batch_size=batch_size, shuffle=True)
        te_loader = DataLoader(TensorDataset(te_x, te_y), batch_size=batch_size, shuffle=False)
        return tr_loader, te_loader

    def get_all_test_loaders(self, batch_size: int) -> List[DataLoader]:
        loaders = []
        for t in range(self.n_tasks):
            te_x, te_y = self.task_test[t]
            loaders.append(DataLoader(TensorDataset(te_x, te_y), batch_size=batch_size, shuffle=False))
        return loaders


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART IV: MODEL â€” Per-Task Encoders + Shared Classifier
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SmallCNNEncoder(nn.Module):
    """Small CNN encoder for MNIST."""
    def __init__(self, embedding_dim: int = 128):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.pool = nn.MaxPool2d(2, 2)
        self.drop = nn.Dropout(p=0.10)
        self.fc = nn.Linear(64 * 7 * 7, embedding_dim)
        self.embedding_dim = embedding_dim

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.drop(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)


class ClassifierHead(nn.Module):
    def __init__(self, embedding_dim: int = 128, n_classes: int = 10):
        super().__init__()
        self.fc = nn.Linear(embedding_dim, n_classes)

    def forward(self, z: torch.Tensor) -> torch.Tensor:
        return self.fc(z)


class HoloNetV3(nn.Module):
    """
    HoloNet v3.0: Per-Task Encoders + Task Inference + Task-Conditioned Retrieval
    
    Key differences from v1.4:
    1. Each task has its own ENCODER (not just adapter)
    2. Task inference at test time using retrieval confidence
    3. No TaskUnpermute - works under true permutation conflict
    """
    
    def __init__(
        self,
        n_tasks: int,
        embedding_dim: int = 128,
        n_classes: int = 10,
    ):
        super().__init__()
        self.n_tasks = n_tasks
        self.embedding_dim = embedding_dim
        self.n_classes = n_classes
        
        # Per-task encoders - each task gets its own encoder
        # Initialize all from the same base, then each will specialize
        self.encoders = nn.ModuleList()
        base_encoder = SmallCNNEncoder(embedding_dim)
        for _ in range(n_tasks):
            # Clone the base encoder for each task
            encoder = SmallCNNEncoder(embedding_dim)
            encoder.load_state_dict(base_encoder.state_dict())
            self.encoders.append(encoder)
        
        # Shared classifier (or could be per-task)
        self.classifier = ClassifierHead(embedding_dim, n_classes)
        
        # Learned temperature for retrieval
        self.retrieval_temp = nn.Parameter(torch.tensor(0.1))
        
    def get_embedding(self, x: torch.Tensor, task_id: int, unit_norm: bool = True) -> torch.Tensor:
        """Get embedding using task-specific encoder."""
        z = self.encoders[task_id](x)
        if unit_norm:
            z = F.normalize(z, dim=-1)
        return z
    
    def forward_logits(self, x: torch.Tensor, task_id: int) -> torch.Tensor:
        """Forward pass for a known task."""
        z = self.get_embedding(x, task_id, unit_norm=False)
        return self.classifier(z)
    
    def freeze_encoder(self, task_id: int):
        """Freeze a specific encoder."""
        for p in self.encoders[task_id].parameters():
            p.requires_grad = False
    
    def unfreeze_encoder(self, task_id: int):
        """Unfreeze a specific encoder."""
        for p in self.encoders[task_id].parameters():
            p.requires_grad = True
    
    def count_trainable_params(self) -> int:
        return sum(p.numel() for p in self.parameters() if p.requires_grad)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART V: TASK INFERENCE ENGINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TaskInferenceEngine:
    """
    Infers the task ID at test time using memory retrieval confidence.
    
    Strategy:
    1. For each known task t, compute embedding using encoder[t]
    2. Query memory restricted to task t
    3. Compute retrieval confidence (max similarity, entropy, etc.)
    4. Return task with highest confidence
    """
    
    def __init__(
        self,
        memory: HoloRAIDMemory,
        n_classes: int = 10,
        top_k: int = 32,
        temperature: float = 0.05,
    ):
        self.memory = memory
        self.n_classes = n_classes
        self.top_k = top_k
        self.temperature = temperature
        
        # Cache for task embeddings
        self._cache: Dict[int, Tuple[torch.Tensor, torch.Tensor]] = {}
        self._cache_valid = False
    
    def invalidate_cache(self):
        self._cache_valid = False
        self._cache.clear()
    
    def rebuild_cache(self, device: torch.device = DEVICE):
        """Rebuild cache of memory embeddings per task."""
        self._cache.clear()
        
        for task_id in self.memory.get_task_ids():
            embs, labels = self.memory.retrieve_all_for_task(task_id)
            if len(embs) > 0:
                self._cache[task_id] = (
                    torch.tensor(embs, dtype=torch.float32, device=device),
                    torch.tensor(labels, dtype=torch.long, device=device),
                )
        
        self._cache_valid = True
    
    def compute_task_confidence(
        self,
        query_embeddings: torch.Tensor,
        task_id: int,
        device: torch.device = DEVICE,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Compute retrieval confidence and class probabilities for a specific task.
        
        Returns:
            confidence: [B] tensor of confidence scores
            probs: [B, n_classes] tensor of class probabilities from retrieval
        """
        B = query_embeddings.shape[0]
        
        if not self._cache_valid:
            self.rebuild_cache(device)
        
        if task_id not in self._cache:
            # No memories for this task - return low confidence
            return (
                torch.zeros(B, device=device),
                torch.ones(B, self.n_classes, device=device) / self.n_classes,
            )
        
        mem_emb, mem_labels = self._cache[task_id]
        
        if mem_emb.shape[0] == 0:
            return (
                torch.zeros(B, device=device),
                torch.ones(B, self.n_classes, device=device) / self.n_classes,
            )
        
        # Compute similarities
        sims = torch.mm(query_embeddings, mem_emb.t())  # [B, M]
        
        # Top-k retrieval
        k = min(self.top_k, sims.shape[1])
        top_sims, top_idx = torch.topk(sims, k, dim=-1)  # [B, k]
        
        # Confidence: max similarity (how well does query match task's memories?)
        confidence = top_sims.max(dim=-1).values  # [B]
        
        # Class probabilities from retrieval
        weights = F.softmax(top_sims / max(self.temperature, 1e-6), dim=-1)  # [B, k]
        top_labels = mem_labels[top_idx]  # [B, k]
        
        probs = torch.zeros(B, self.n_classes, device=device)
        probs.scatter_add_(1, top_labels, weights)
        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)
        
        return confidence, probs
    
    def infer_task(
        self,
        model: HoloNetV3,
        x: torch.Tensor,
        known_tasks: List[int],
        device: torch.device = DEVICE,
    ) -> Tuple[torch.Tensor, Dict[int, torch.Tensor], Dict[int, torch.Tensor]]:
        """
        Infer task ID for input x.
        
        Returns:
            inferred_tasks: [B] tensor of inferred task IDs
            confidences: dict mapping task_id -> [B] confidence tensor
            probs: dict mapping task_id -> [B, n_classes] probability tensor
        """
        if not self._cache_valid:
            self.rebuild_cache(device)
        
        B = x.shape[0]
        
        all_confidences = {}
        all_probs = {}
        
        for task_id in known_tasks:
            # Compute embedding using this task's encoder
            with torch.no_grad():
                z = model.get_embedding(x, task_id, unit_norm=True)
            
            # Query memory for this task
            conf, probs = self.compute_task_confidence(z, task_id, device)
            all_confidences[task_id] = conf
            all_probs[task_id] = probs
        
        # Stack confidences and find argmax
        conf_stack = torch.stack([all_confidences[t] for t in known_tasks], dim=1)  # [B, T]
        inferred_idx = conf_stack.argmax(dim=1)  # [B]
        inferred_tasks = torch.tensor([known_tasks[i] for i in inferred_idx], device=device)
        
        return inferred_tasks, all_confidences, all_probs


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART VI: TRAINING AND EVALUATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def store_task_to_memory(
    model: HoloNetV3,
    loader: DataLoader,
    memory: HoloRAIDMemory,
    task_id: int,
    device: torch.device = DEVICE,
) -> int:
    """Store embeddings for a task using its specific encoder."""
    model.eval()
    n = 0
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            z_unit = model.get_embedding(x, task_id=task_id, unit_norm=True)
            for i in range(z_unit.shape[0]):
                memory.store(z_unit[i].cpu().numpy(), int(y[i].item()), task_id=task_id)
                n += 1
    return n


def train_epoch(
    model: HoloNetV3,
    loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    task_id: int,
    device: torch.device = DEVICE,
) -> float:
    """Train model on a single task."""
    model.train()
    criterion = nn.CrossEntropyLoss()
    total_loss = 0.0
    steps = 0
    
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        
        logits = model.forward_logits(x, task_id=task_id)
        loss = criterion(logits, y)
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        steps += 1
    
    return total_loss / max(1, steps)


@torch.no_grad()
def evaluate_with_task_oracle(
    model: HoloNetV3,
    loader: DataLoader,
    task_id: int,
    device: torch.device = DEVICE,
) -> float:
    """Evaluate with known task ID (model-only, no memory)."""
    model.eval()
    correct, total = 0, 0
    
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        logits = model.forward_logits(x, task_id=task_id)
        pred = logits.argmax(dim=-1)
        correct += (pred == y).sum().item()
        total += y.size(0)
    
    return correct / max(1, total)


@torch.no_grad()
def evaluate_with_task_inference(
    model: HoloNetV3,
    loader: DataLoader,
    task_inference: TaskInferenceEngine,
    known_tasks: List[int],
    true_task_id: int,
    use_memory: bool = True,
    memory_weight: float = 0.5,
    device: torch.device = DEVICE,
) -> Tuple[float, float]:
    """
    Evaluate using task inference.
    
    Returns:
        accuracy: classification accuracy
        task_inference_accuracy: how often the correct task was inferred
    """
    model.eval()
    correct, total = 0, 0
    task_correct = 0
    
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        B = x.shape[0]
        
        # Infer task
        inferred_tasks, confidences, mem_probs = task_inference.infer_task(
            model, x, known_tasks, device
        )
        
        # Check task inference accuracy
        task_correct += (inferred_tasks == true_task_id).sum().item()
        
        # Get predictions using inferred task
        for i in range(B):
            t = inferred_tasks[i].item()
            
            # Model prediction
            logits = model.forward_logits(x[i:i+1], task_id=t)
            model_probs = F.softmax(logits, dim=-1)
            
            if use_memory and t in mem_probs:
                # Combine with memory
                mem_p = mem_probs[t][i:i+1]
                combined = (1 - memory_weight) * model_probs + memory_weight * mem_p
                pred = combined.argmax(dim=-1)
            else:
                pred = model_probs.argmax(dim=-1)
            
            correct += (pred == y[i:i+1]).sum().item()
        
        total += B
    
    return correct / max(1, total), task_correct / max(1, total)


def compute_forgetting(task_accuracies: List[List[float]]) -> float:
    """Compute average forgetting across tasks."""
    if len(task_accuracies) < 2:
        return 0.0
    T = len(task_accuracies)
    total, count = 0.0, 0
    for t in range(T - 1):
        best = max(task_accuracies[s][t] for s in range(t, T) if t < len(task_accuracies[s]))
        final = task_accuracies[-1][t]
        total += (best - final)
        count += 1
    return total / max(1, count)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PART VII: MAIN EXPERIMENT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class ExperimentConfig:
    n_tasks: int = 10
    n_train_per_task: int = 3000
    n_test_per_task: int = 500
    batch_size: int = 64
    epochs_per_task: int = 3
    embedding_dim: int = 128
    lr: float = 1e-3
    memory_size_cap: int = 5000
    holoraid_n: int = 5
    holoraid_k: int = 3
    retrieval_top_k: int = 32
    retrieval_temp: float = 0.05
    memory_weight: float = 0.5
    seed: int = 42


def run_holonet_v3(cfg: ExperimentConfig, data: PermutedMNIST) -> Dict[str, Any]:
    """Run HoloNet v3.0 with per-task encoders and task inference."""
    print("\n" + "â”€" * 70)
    print("  HoloNet v3.0 (Per-Task Encoders + Task Inference)")
    print("â”€" * 70)
    
    model = HoloNetV3(cfg.n_tasks, cfg.embedding_dim).to(DEVICE)
    
    mcfg = HoloRAIDConfig(n_shards=cfg.holoraid_n, k_threshold=cfg.holoraid_k, seed=cfg.seed)
    memory = HoloRAIDMemory(mcfg, cfg.embedding_dim)
    
    task_inference = TaskInferenceEngine(
        memory,
        n_classes=10,
        top_k=cfg.retrieval_top_k,
        temperature=cfg.retrieval_temp,
    )
    
    test_loaders = data.get_all_test_loaders(cfg.batch_size)
    
    results = {
        "task_accuracies_oracle": [],      # With task oracle (model only)
        "task_accuracies_inferred": [],    # With task inference + memory
        "task_inference_accuracies": [],   # How well we infer the task
        "avg_accuracies_oracle": [],
        "avg_accuracies_inferred": [],
        "memory_sizes": [],
    }
    
    known_tasks = []
    
    for t in range(cfg.n_tasks):
        print(f"\n  Training Task {t}...")
        tr_loader, _ = data.get_task_loaders(t, cfg.batch_size)
        
        # Only train encoder[t] and classifier
        # Freeze all other encoders
        for i in range(cfg.n_tasks):
            if i == t:
                model.unfreeze_encoder(i)
            else:
                model.freeze_encoder(i)
        
        # Optimizer for encoder[t] and classifier
        params = list(model.encoders[t].parameters()) + list(model.classifier.parameters())
        optimizer = torch.optim.Adam(params, lr=cfg.lr)
        
        for epoch in range(cfg.epochs_per_task):
            loss = train_epoch(model, tr_loader, optimizer, task_id=t, device=DEVICE)
        
        # Store memories using encoder[t]
        n_stored = store_task_to_memory(model, tr_loader, memory, task_id=t, device=DEVICE)
        
        # Prune if needed
        if len(memory) > cfg.memory_size_cap:
            memory.prune_to_size(cfg.memory_size_cap, strategy="per_task_class")
        
        # Rebuild cache
        task_inference.invalidate_cache()
        
        known_tasks.append(t)
        results["memory_sizes"].append(len(memory))
        
        # Evaluate on all seen tasks
        accs_oracle = []
        accs_inferred = []
        task_inf_accs = []
        
        for j in range(t + 1):
            # Oracle accuracy (model only, known task)
            acc_oracle = evaluate_with_task_oracle(model, test_loaders[j], task_id=j, device=DEVICE)
            
            # Inferred accuracy (task inference + memory)
            acc_inferred, task_inf_acc = evaluate_with_task_inference(
                model, test_loaders[j], task_inference, known_tasks, 
                true_task_id=j, use_memory=True, memory_weight=cfg.memory_weight, device=DEVICE
            )
            
            accs_oracle.append(acc_oracle)
            accs_inferred.append(acc_inferred)
            task_inf_accs.append(task_inf_acc)
        
        results["task_accuracies_oracle"].append(accs_oracle)
        results["task_accuracies_inferred"].append(accs_inferred)
        results["task_inference_accuracies"].append(task_inf_accs)
        
        avg_oracle = np.mean(accs_oracle)
        avg_inferred = np.mean(accs_inferred)
        avg_task_inf = np.mean(task_inf_accs)
        
        results["avg_accuracies_oracle"].append(avg_oracle)
        results["avg_accuracies_inferred"].append(avg_inferred)
        
        print(f"  Task {t}: Oracle={avg_oracle*100:.1f}%, Inferred={avg_inferred*100:.1f}%, "
              f"TaskInf={avg_task_inf*100:.1f}%, Mem={len(memory)}")
    
    results["forgetting_oracle"] = compute_forgetting(results["task_accuracies_oracle"])
    results["forgetting_inferred"] = compute_forgetting(results["task_accuracies_inferred"])
    
    return results


def run_baseline_naive_ft(cfg: ExperimentConfig, data: PermutedMNIST) -> Dict[str, Any]:
    """Baseline: Naive fine-tuning with single encoder."""
    print("\n" + "â”€" * 70)
    print("  Baseline: Naive Fine-Tuning")
    print("â”€" * 70)
    
    encoder = SmallCNNEncoder(cfg.embedding_dim).to(DEVICE)
    classifier = ClassifierHead(cfg.embedding_dim, 10).to(DEVICE)
    
    test_loaders = data.get_all_test_loaders(cfg.batch_size)
    
    results = {"task_accuracies": [], "avg_accuracies": []}
    
    for t in range(cfg.n_tasks):
        tr_loader, _ = data.get_task_loaders(t, cfg.batch_size)
        
        optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=cfg.lr)
        criterion = nn.CrossEntropyLoss()
        
        encoder.train()
        classifier.train()
        for _ in range(cfg.epochs_per_task):
            for x, y in tr_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                optimizer.zero_grad()
                z = encoder(x)
                logits = classifier(z)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()
        
        # Evaluate
        encoder.eval()
        classifier.eval()
        accs = []
        for j in range(t + 1):
            correct, total = 0, 0
            with torch.no_grad():
                for x, y in test_loaders[j]:
                    x, y = x.to(DEVICE), y.to(DEVICE)
                    z = encoder(x)
                    logits = classifier(z)
                    pred = logits.argmax(dim=-1)
                    correct += (pred == y).sum().item()
                    total += y.size(0)
            accs.append(correct / max(1, total))
        
        results["task_accuracies"].append(accs)
        results["avg_accuracies"].append(np.mean(accs))
        print(f"  Task {t}: AvgAcc = {np.mean(accs)*100:.1f}%")
    
    results["forgetting"] = compute_forgetting(results["task_accuracies"])
    return results


def run_baseline_replay(cfg: ExperimentConfig, data: PermutedMNIST) -> Dict[str, Any]:
    """Baseline: Replay buffer."""
    print("\n" + "â”€" * 70)
    print("  Baseline: Replay Buffer")
    print("â”€" * 70)
    
    encoder = SmallCNNEncoder(cfg.embedding_dim).to(DEVICE)
    classifier = ClassifierHead(cfg.embedding_dim, 10).to(DEVICE)
    
    test_loaders = data.get_all_test_loaders(cfg.batch_size)
    
    rng = np.random.default_rng(cfg.seed)
    cap = cfg.memory_size_cap
    replay_x, replay_y = [], []
    seen = 0
    
    results = {"task_accuracies": [], "avg_accuracies": []}
    
    for t in range(cfg.n_tasks):
        tr_loader, _ = data.get_task_loaders(t, cfg.batch_size)
        
        # Add to replay buffer (reservoir sampling)
        for x, y in tr_loader:
            for i in range(x.size(0)):
                seen += 1
                if len(replay_x) < cap:
                    replay_x.append(x[i].cpu())
                    replay_y.append(y[i].cpu())
                else:
                    j = int(rng.integers(0, seen))
                    if j < cap:
                        replay_x[j] = x[i].cpu()
                        replay_y[j] = y[i].cpu()
        
        # Train on replay buffer
        all_x = torch.stack(replay_x)
        all_y = torch.stack(replay_y)
        replay_loader = DataLoader(TensorDataset(all_x, all_y), batch_size=cfg.batch_size, shuffle=True)
        
        optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=cfg.lr)
        criterion = nn.CrossEntropyLoss()
        
        encoder.train()
        classifier.train()
        for _ in range(cfg.epochs_per_task):
            for x, y in replay_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                optimizer.zero_grad()
                z = encoder(x)
                logits = classifier(z)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()
        
        # Evaluate
        encoder.eval()
        classifier.eval()
        accs = []
        for j in range(t + 1):
            correct, total = 0, 0
            with torch.no_grad():
                for x, y in test_loaders[j]:
                    x, y = x.to(DEVICE), y.to(DEVICE)
                    z = encoder(x)
                    logits = classifier(z)
                    pred = logits.argmax(dim=-1)
                    correct += (pred == y).sum().item()
                    total += y.size(0)
            accs.append(correct / max(1, total))
        
        results["task_accuracies"].append(accs)
        results["avg_accuracies"].append(np.mean(accs))
        print(f"  Task {t}: AvgAcc = {np.mean(accs)*100:.1f}%, Buffer = {len(replay_x)}")
    
    results["forgetting"] = compute_forgetting(results["task_accuracies"])
    return results


def run_baseline_per_task_heads(cfg: ExperimentConfig, data: PermutedMNIST) -> Dict[str, Any]:
    """Baseline: Per-task heads with frozen encoder (after task 0)."""
    print("\n" + "â”€" * 70)
    print("  Baseline: Per-Task Heads (Frozen Encoder)")
    print("â”€" * 70)
    
    encoder = SmallCNNEncoder(cfg.embedding_dim).to(DEVICE)
    classifiers = nn.ModuleList([ClassifierHead(cfg.embedding_dim, 10) for _ in range(cfg.n_tasks)]).to(DEVICE)
    
    test_loaders = data.get_all_test_loaders(cfg.batch_size)
    
    results = {"task_accuracies": [], "avg_accuracies": []}
    
    for t in range(cfg.n_tasks):
        tr_loader, _ = data.get_task_loaders(t, cfg.batch_size)
        
        if t == 0:
            # Train encoder on task 0
            params = list(encoder.parameters()) + list(classifiers[t].parameters())
        else:
            # Freeze encoder, only train new head
            for p in encoder.parameters():
                p.requires_grad = False
            params = list(classifiers[t].parameters())
        
        optimizer = torch.optim.Adam(params, lr=cfg.lr)
        criterion = nn.CrossEntropyLoss()
        
        encoder.train() if t == 0 else encoder.eval()
        classifiers[t].train()
        
        for _ in range(cfg.epochs_per_task):
            for x, y in tr_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                optimizer.zero_grad()
                z = encoder(x)
                logits = classifiers[t](z)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()
        
        # Evaluate (need to pick which head to use - use oracle)
        encoder.eval()
        accs = []
        for j in range(t + 1):
            classifiers[j].eval()
            correct, total = 0, 0
            with torch.no_grad():
                for x, y in test_loaders[j]:
                    x, y = x.to(DEVICE), y.to(DEVICE)
                    z = encoder(x)
                    logits = classifiers[j](z)
                    pred = logits.argmax(dim=-1)
                    correct += (pred == y).sum().item()
                    total += y.size(0)
            accs.append(correct / max(1, total))
        
        results["task_accuracies"].append(accs)
        results["avg_accuracies"].append(np.mean(accs))
        print(f"  Task {t}: AvgAcc = {np.mean(accs)*100:.1f}%")
    
    results["forgetting"] = compute_forgetting(results["task_accuracies"])
    return results


def plot_results(all_results: Dict[str, Dict[str, Any]], cfg: ExperimentConfig):
    """Generate visualization."""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # Plot 1: Average accuracy over time
    ax = axes[0, 0]
    for name, res in all_results.items():
        if "avg_accuracies" in res:
            accs = res["avg_accuracies"]
        elif "avg_accuracies_inferred" in res:
            accs = res["avg_accuracies_inferred"]
        else:
            continue
        ax.plot(range(len(accs)), [a*100 for a in accs], 'o-', label=name, linewidth=2, markersize=6)
    ax.set_xlabel("Task", fontsize=11)
    ax.set_ylabel("Average Accuracy (%)", fontsize=11)
    ax.set_title("Average Accuracy Across Tasks", fontsize=12, fontweight='bold')
    ax.legend(fontsize=9)
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 105)
    
    # Plot 2: Final per-task accuracy
    ax = axes[0, 1]
    x = np.arange(cfg.n_tasks)
    width = 0.2
    offset = 0
    for name, res in all_results.items():
        if "task_accuracies" in res:
            final = res["task_accuracies"][-1]
        elif "task_accuracies_inferred" in res:
            final = res["task_accuracies_inferred"][-1]
        else:
            continue
        ax.bar(x + offset * width, [a*100 for a in final], width, label=name, alpha=0.8)
        offset += 1
    ax.set_xlabel("Task", fontsize=11)
    ax.set_ylabel("Accuracy (%)", fontsize=11)
    ax.set_title("Final Per-Task Accuracy", fontsize=12, fontweight='bold')
    ax.legend(fontsize=9)
    ax.set_ylim(0, 105)
    
    # Plot 3: Forgetting comparison
    ax = axes[1, 0]
    names = []
    forgets = []
    for name, res in all_results.items():
        if "forgetting" in res:
            names.append(name)
            forgets.append(res["forgetting"] * 100)
        elif "forgetting_inferred" in res:
            names.append(name)
            forgets.append(res["forgetting_inferred"] * 100)
    bars = ax.bar(names, forgets, alpha=0.8, color=['#4C72B0', '#55A868', '#C44E52', '#8172B3'][:len(names)])
    ax.set_ylabel("Forgetting (%)", fontsize=11)
    ax.set_title("Forgetting (Lower is Better)", fontsize=12, fontweight='bold')
    plt.setp(ax.get_xticklabels(), rotation=15, ha='right')
    for bar, v in zip(bars, forgets):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                f'{v:.1f}%', ha='center', va='bottom', fontsize=10)
    
    # Plot 4: HoloNet task inference accuracy
    ax = axes[1, 1]
    if "HoloNet v3.0" in all_results and "task_inference_accuracies" in all_results["HoloNet v3.0"]:
        task_inf = all_results["HoloNet v3.0"]["task_inference_accuracies"]
        # Plot final task inference accuracy for each task
        final_inf = task_inf[-1]
        ax.bar(range(len(final_inf)), [a*100 for a in final_inf], alpha=0.8, color='#8172B3')
        ax.set_xlabel("Task", fontsize=11)
        ax.set_ylabel("Task Inference Accuracy (%)", fontsize=11)
        ax.set_title("HoloNet: Task Inference Accuracy", fontsize=12, fontweight='bold')
        ax.set_ylim(0, 105)
        ax.axhline(y=100, linestyle='--', color='green', alpha=0.5)
    else:
        ax.text(0.5, 0.5, "No task inference data", ha='center', va='center', transform=ax.transAxes)
    
    plt.tight_layout()
    plt.savefig("holonet_v3_results.png", dpi=150, bbox_inches='tight')
    plt.show()
    print("\n  âœ“ Saved: holonet_v3_results.png")


def main():
    banner()
    
    print("  â•­" + "â”€" * 76 + "â•®")
    print("  â”‚" + " " * 76 + "â”‚")
    print("  â”‚" + "   ðŸ§  HoloNet v3.0: Per-Task Encoders + Task Inference".center(76) + "â”‚")
    print("  â”‚" + " " * 76 + "â”‚")
    print("  â”‚" + "   Permuted MNIST â€¢ 10 Tasks â€¢ NO TaskUnpermute".center(76) + "â”‚")
    print("  â”‚" + " " * 76 + "â”‚")
    print("  â•°" + "â”€" * 76 + "â•¯")
    
    cfg = ExperimentConfig()
    
    print("\n  Configuration:")
    print(f"    Tasks: {cfg.n_tasks}")
    print(f"    Train/task: {cfg.n_train_per_task}, Test/task: {cfg.n_test_per_task}")
    print(f"    Epochs/task: {cfg.epochs_per_task}")
    print(f"    HoloRAID: {cfg.holoraid_k}-of-{cfg.holoraid_n}")
    print(f"    Memory cap: {cfg.memory_size_cap}")
    print(f"    Memory weight: {cfg.memory_weight}")
    
    print("\n  Loading Permuted MNIST (NO canonicalization)...")
    data = PermutedMNIST(n_tasks=cfg.n_tasks, n_train=cfg.n_train_per_task, 
                          n_test=cfg.n_test_per_task, seed=cfg.seed)
    print("  âœ“ Data loaded")
    
    all_results = {}
    
    # Baselines
    all_results["Naive FT"] = run_baseline_naive_ft(cfg, data)
    all_results["Replay"] = run_baseline_replay(cfg, data)
    all_results["Per-Task Heads"] = run_baseline_per_task_heads(cfg, data)
    
    # Our method
    all_results["HoloNet v3.0"] = run_holonet_v3(cfg, data)
    
    # Print summary
    print("\n" + "â–ˆ" * 80)
    print("â–ˆ  FINAL RESULTS" + " " * 62 + "â–ˆ")
    print("â–ˆ" * 80)
    
    print("\n  Method                Final Acc    Forgetting")
    print("  " + "â”€" * 45)
    
    for name, res in all_results.items():
        if "avg_accuracies" in res:
            acc = res["avg_accuracies"][-1] * 100
            forg = res.get("forgetting", 0) * 100
        elif "avg_accuracies_inferred" in res:
            acc = res["avg_accuracies_inferred"][-1] * 100
            forg = res.get("forgetting_inferred", 0) * 100
        else:
            continue
        print(f"  {name:20s} {acc:8.1f}%    {forg:8.1f}%")
    
    # HoloNet-specific stats
    if "HoloNet v3.0" in all_results:
        holonet = all_results["HoloNet v3.0"]
        print("\n  HoloNet v3.0 Details:")
        print(f"    Oracle Acc (model only):    {holonet['avg_accuracies_oracle'][-1]*100:.1f}%")
        print(f"    Inferred Acc (with memory): {holonet['avg_accuracies_inferred'][-1]*100:.1f}%")
        
        # Task inference accuracy
        if holonet["task_inference_accuracies"]:
            avg_task_inf = np.mean(holonet["task_inference_accuracies"][-1])
            print(f"    Task Inference Accuracy:    {avg_task_inf*100:.1f}%")
    
    # Plot
    print("\n  Generating visualizations...")
    plot_results(all_results, cfg)
    
    print("\n" + "â–ˆ" * 80)
    print("â–ˆ" + "  âœ“ HoloNet v3.0 uses per-task encoders to handle permutation conflict".center(78) + "â–ˆ")
    print("â–ˆ" + "  âœ“ Task inference uses memory retrieval confidence".center(78) + "â–ˆ")
    print("â–ˆ" + "  âœ“ No TaskUnpermute required - true continual learning".center(78) + "â–ˆ")
    print("â–ˆ" * 80)
    
    return all_results


if __name__ == "__main__":
    results = main()
